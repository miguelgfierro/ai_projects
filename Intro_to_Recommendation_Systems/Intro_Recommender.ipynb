{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Recommendation Systems\n",
    "\n",
    "In this tutorial we are going to use a [deep autoencoder](https://arxiv.org/abs/1708.01715) to perform collaborative filtering in the [Netflix dataset](https://netflixprize.com/). \n",
    "\n",
    "[Collaborative filtering](https://en.wikipedia.org/wiki/Collaborative_filtering) is one of the most pupular techniques in recommendation systems. It is based on inferring the missing entries in an `mxn` matrix, `R`, whose `(i, j)` entry describes the ratings given by the `ith` user to the `jth` item. The performance is then measured using Root\n",
    "Mean Squared Error (RMSE).\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/5/52/Collaborative_filtering.gif\" width=300px/>\n",
    "</p>\n",
    "\n",
    "The code in this tutorial is done with [PyTorch](http://pytorch.org/) and is based on [this repo](https://github.com/NVIDIA/DeepRecommender) by NVIDIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.4 | packaged by conda-forge | (default, Nov  4 2017, 10:11:29) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "PyTorch:  0.3.0.post4\n",
      "Numpy:  1.14.0\n",
      "Number of CPU processors:  24\n",
      "GPU:  ['Tesla M60', 'Tesla M60', 'Tesla M60', 'Tesla M60']\n",
      "GPU memory:  ['8123 MiB', '8123 MiB', '8123 MiB', '8123 MiB']\n",
      "CUDA:  CUDA Version 8.0.61\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from utils import get_gpu_name, get_number_processors, get_gpu_memory, get_cuda_version\n",
    "\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"Number of CPU processors: \", get_number_processors())\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(\"GPU memory: \", get_gpu_memory())\n",
    "print(\"CUDA: \", get_cuda_version())\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Netflix\n",
    "\n",
    "This dataset was constructed to support participants in the [Netflix Prize](http://www.netflixprize.com). The movie rating files contain over 100 million ratings from 480 thousand randomly-chosen, anonymous Netflix customers over 17 thousand movie titles.  The data were collected between October, 1998 and December, 2005 and reflect the distribution of all ratings received during this period.  The ratings are on a scale from 1 to 5 (integral) stars.\n",
    "\n",
    "The dataset can be [downloaded here](http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a). To uncompress it:\n",
    "\n",
    "```bash\n",
    "tar -xvf nf_prize_dataset.tar.gz\n",
    "tar -xf download/training_set.tar\n",
    "```\n",
    "\n",
    "When we download the data, there are two important files:\n",
    "\n",
    "1) The file `training_set.tar` is a tar of a directory containing 17770 files, one per movie.  The first line of each file contains the movie id followed by a colon.  Each subsequent line in the file corresponds to a rating from a customer and its date in the following format:\n",
    "\n",
    "CustomerID,Rating,Date\n",
    "- MovieIDs range from 1 to 17770 sequentially.\n",
    "- CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users.\n",
    "- Ratings are on a five star (integral) scale from 1 to 5.\n",
    "- Dates have the format YYYY-MM-DD.\n",
    "\n",
    "2) Movie information in `movie_titles.txt` is in the following format:\n",
    "\n",
    "MovieID,YearOfRelease,Title\n",
    "\n",
    "- MovieID do not correspond to actual Netflix movie ids or IMDB movie ids.\n",
    "- YearOfRelease can range from 1890 to 2005 and may correspond to the release of corresponding DVD, not necessarily its theaterical release.\n",
    "- Title in English is the Netflix movie.\n",
    "\n",
    "### Data prep\n",
    "\n",
    "The first step is to covert the data to the correct format for the autoencoder to read. This can take between 1 to 2 hours.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/datadrive'\n",
    "NF_PRIZE_DATASET = os.path.join(DATA_ROOT, 'netflix','download','training_set') #location of extracted data\n",
    "NF_DATA = 'Netflix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%run ./DeepRecommender/data_utils/netflix_data_convert.py $NF_PRIZE_DATASET $NF_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script splitted the data into train, test and validation set, creating files with three columns: `CustomerID,MovieID,Rating`. The data is splitted over time generating 4 datasets: Netflix 3months, Netflix 6 months, Netflix 1 year and Netflix full. Here there is a table with some details of each dataset:\n",
    "\n",
    "| Dataset  | Netflix 3 months | Netflix 6 months | Netflix 1 year | Netflix full |\n",
    "| -------- | ---------------- | ---------------- | ----------- |  ------------ |\n",
    "| Ratings train | 13,675,402 | 29,179,009 | 41,451,832 | 98,074,901 |\n",
    "| Users train | 311,315 |390,795  | 345,855 | 477,412 |\n",
    "| Items train | 17,736 |17,757  | 16,907 | 17,768 |\n",
    "| Time range train | 2005-09-01 to 2005-11-31 | 2005-06-01 to 2005-11-31 | 2004-06-01 to 2005-05-31 | 1999-12-01 to 2005-11-31\n",
    "|  |  |  |   | |\n",
    "| Ratings test | 2,082,559 | 2,175,535  | 3,888,684| 2,250,481 |\n",
    "| Users test | 160,906 | 169,541  | 197,951| 173,482 |\n",
    "| Items test | 17,261 | 17,290  | 16,506| 17,305 |\n",
    "| Time range test | 2005-12-01 to 2005-12-31 | 2005-12-01 to 2005-12-31 | 2005-06-01 to 2005-06-31 | 2005-12-01 to 2005-12-31\n",
    "\n",
    "Let's take a look at one of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1041739, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1549</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5144</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7716</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8348</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4635</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  MovieID  Rating\n",
       "0           0     1549     1.0\n",
       "1           0     5144     2.0\n",
       "2           0     7716     3.0\n",
       "3           0     8348     3.0\n",
       "4           0     4635     2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_3m_valid = os.path.join(NF_DATA, 'N3M_VALID', 'n3m.valid.txt')\n",
    "df = pd.read_csv(nf_3m_valid, names=['CustomerID','MovieID','Rating'], sep='\\t')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoder for Collaborative Filtering\n",
    "\n",
    "Once we have the data, let's explain in some detail the model that we are going to use. The [model](https://arxiv.org/abs/1708.01715) developed by NVIDIA folks is a Deep autoencoder with 6 layers with non-linear activation function SELU (scaled exponential linear units), dropout and iterative dense refeeding.\n",
    "\n",
    "An autoencoder is a network which implements two transformations: $encode(x) : R^n → R^d$ and $decoder(z) : R^d → R^n$. The “goal” of autoenoder is to obtain a $d$ dimensional representation of data such that an error measure between $x$ and $f(x) = decode(encode(x))$ is minimized. In the next figure, the autocoder architecture proposed in the [paper](https://arxiv.org/abs/1708.01715) is showed. Encoder has 2 layers $e_1$ and $e_2$ and decoder has 2 layers $d_1$ and $d_2$. Dropout may be applied to coding layer $z$. In the paper, the authors show experiments with different number of layers, from 2 to 12 (see Table 2 in the original paper).\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./data/AutoEncoder.png\" width=350px/>\n",
    "</p>\n",
    "\n",
    "During the forward pass the model takes a user representation by his vector of ratings from the training set $x \\in R^n$, where $n$ is number of items. Note that $x$ is very sparse, while the output of the decoder, $y=f(x) \\in R^n$ is dense and contains the rating predictions for all items in the corpus. The loss is the root mean squared error (RMSE).\n",
    "\n",
    "One of the key ideas of the paper is dense re-feeding. Let's consider an idealized scenario with a perfect $f$. Then $f(x)_i = x_i ,∀i : x_i \\ne 0$ and $f(x)_i$ accurately predicts all user's future ratings. This means that if a user rates a new item $k$ (thereby creating a new vector $x'$) then $f(x)_k = x'_k$ and $f(x) = f(x')$. Therefore, the authors refeed the input in the autoencoder to augment the dataset. The method consists of the following steps:\n",
    "\n",
    "1. Given a sparse $x$, compute the forward pass to get $f(x)$ and the loss.\n",
    "\n",
    "2. Backpropagate the loss and update the weights.\n",
    "\n",
    "3. Treat $f(x)$ as a new example and compute $f(f(x))$\n",
    "\n",
    "4. Compute a second backward pass.\n",
    "\n",
    "Steps 3 and 4 can be repeated several times.\n",
    "\n",
    "Finally, the authors explore different non-linear [activation functions](https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py). They found that on this task ELU, SELU and LRELU, which have non-zero negative parts, perform much better than SIGMOID, RELU, RELU6, and TANH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "TRAIN = os.path.join(NF_DATA, 'N3M_TRAIN') #os.path.join(NF_DATA, 'NF_TRAIN')\n",
    "EVAL = os.path.join(NF_DATA, 'N3M_VALID') #os.path.join(NF_DATA, 'NF_VALID')\n",
    "TEST = os.path.join(NF_DATA, 'N3M_TEST') #os.path.join(NF_DATA, 'NF_TEST')\n",
    "GPUS = 0 #'0,1,2,3'\n",
    "ACTIVATION = 'selu'\n",
    "OPTIMIZER = 'momentum'\n",
    "HIDDEN = '512,512,1024'\n",
    "BATCH_SIZE = 128\n",
    "DROPOUT = 0.8\n",
    "LR = 0.005\n",
    "WD = 0\n",
    "EPOCHS = 10\n",
    "AUG_STEP = 1\n",
    "MODEL_OUTPUT_DIR = 'model_save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(aug_step=1, batch_size=128, constrained=False, drop_prob=0.8, gpu_ids='0', hidden_layers='512,512,1024', logdir='model_save', lr=0.005, noise_prob=0.0, non_linearity_type='selu', num_epochs=10, optimizer='momentum', path_to_eval_data='Netflix/N3M_VALID', path_to_train_data='Netflix/N3M_TRAIN', skip_last_layer_nl=False, weight_decay=0.0)\n",
      "Loading training data from Netflix/N3M_TRAIN\n",
      "Data loaded\n",
      "Total items found: 311315\n",
      "Vector dim: 17736\n",
      "Loading eval data from Netflix/N3M_VALID\n",
      "******************************\n",
      "******************************\n",
      "[17736, 512, 512, 1024]\n",
      "Dropout drop probability: 0.8\n",
      "Encoder pass:\n",
      "torch.Size([512, 17736])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([1024])\n",
      "Decoder pass:\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([17736, 512])\n",
      "torch.Size([17736])\n",
      "******************************\n",
      "******************************\n",
      "Using GPUs: [0]\n",
      "Doing epoch 0 of 10\n",
      "Total epoch 0 finished in 69.39120125770569 seconds with TRAINING RMSE loss: 1.1183533288603893\n",
      "Epoch 0 EVALUATION LOSS: 0.997187149064757\n",
      "Doing epoch 1 of 10\n",
      "Total epoch 1 finished in 69.05308318138123 seconds with TRAINING RMSE loss: 0.9789836858425376\n",
      "Epoch 1 EVALUATION LOSS: 0.9830844731127444\n",
      "Doing epoch 2 of 10\n",
      "Total epoch 2 finished in 68.9950942993164 seconds with TRAINING RMSE loss: 0.9593065493420863\n",
      "Epoch 2 EVALUATION LOSS: 0.98861261075587\n",
      "Doing epoch 3 of 10\n",
      "Total epoch 3 finished in 69.13668775558472 seconds with TRAINING RMSE loss: 0.9464339257342224\n",
      "Epoch 3 EVALUATION LOSS: 0.9762008394628371\n",
      "Doing epoch 4 of 10\n",
      "Total epoch 4 finished in 69.09636783599854 seconds with TRAINING RMSE loss: 0.9355610656442712\n",
      "Epoch 4 EVALUATION LOSS: 0.9808872814542353\n",
      "Doing epoch 5 of 10\n",
      "Total epoch 5 finished in 69.17095017433167 seconds with TRAINING RMSE loss: 0.9258845933913559\n",
      "Epoch 5 EVALUATION LOSS: 0.9842890565637975\n",
      "Doing epoch 6 of 10\n",
      "Total epoch 6 finished in 69.08278322219849 seconds with TRAINING RMSE loss: 0.9622985019130311\n",
      "Epoch 6 EVALUATION LOSS: 0.9838701840431763\n",
      "Doing epoch 7 of 10\n",
      "Total epoch 7 finished in 69.04743361473083 seconds with TRAINING RMSE loss: 0.9337027765558531\n",
      "Epoch 7 EVALUATION LOSS: 0.984365107262594\n",
      "Doing epoch 8 of 10\n",
      "Total epoch 8 finished in 69.1117844581604 seconds with TRAINING RMSE loss: 0.9205498934527924\n",
      "Epoch 8 EVALUATION LOSS: 0.9750949946703523\n",
      "Doing epoch 9 of 10\n",
      "Total epoch 9 finished in 69.13744783401489 seconds with TRAINING RMSE loss: 0.9099730840527471\n",
      "Epoch 9 EVALUATION LOSS: 0.9742177051690417\n",
      "Saving model to model_save/model.epoch_9\n",
      "Routine finished. Process time 2747.513389825821 s\n"
     ]
    }
   ],
   "source": [
    "%run ./DeepRecommender/run.py --gpu_ids $GPUS \\\n",
    "    --path_to_train_data $TRAIN \\\n",
    "    --path_to_eval_data $EVAL \\\n",
    "    --hidden_layers $HIDDEN \\\n",
    "    --non_linearity_type $ACTIVATION \\\n",
    "    --batch_size $BATCH_SIZE \\\n",
    "    --logdir $MODEL_OUTPUT_DIR \\\n",
    "    --drop_prob $DROPOUT \\\n",
    "    --optimizer $OPTIMIZER \\\n",
    "    --lr $LR \\\n",
    "    --weight_decay $WD \\\n",
    "    --aug_step $AUG_STEP \\\n",
    "    --num_epochs $EPOCHS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Now we are going to evaluate the model on the test set and compute the final loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_OUTPUT = 'preds.txt'\n",
    "MODEL_PATH = os.path.join(MODEL_OUTPUT_DIR, 'model.epoch_' + str(EPOCHS-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(constrained=False, drop_prob=0.8, hidden_layers='512,512,1024', non_linearity_type='selu', path_to_eval_data='Netflix/N3M_TEST', path_to_train_data='Netflix/N3M_TRAIN', predictions_path='preds.txt', save_path='model_save/model.epoch_9', skip_last_layer_nl=False)\n",
      "Loading training data\n",
      "Data loaded\n",
      "Total items found: 311315\n",
      "Vector dim: 17736\n",
      "Loading eval data\n",
      "******************************\n",
      "******************************\n",
      "[17736, 512, 512, 1024]\n",
      "Dropout drop probability: 0.8\n",
      "Encoder pass:\n",
      "torch.Size([512, 17736])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([1024])\n",
      "Decoder pass:\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([17736, 512])\n",
      "torch.Size([17736])\n",
      "******************************\n",
      "******************************\n",
      "Loading model from: model_save/model.epoch_9\n",
      "Done: 0\n",
      "Done: 10000\n",
      "Done: 20000\n",
      "Done: 30000\n",
      "Done: 40000\n",
      "Done: 50000\n",
      "Done: 60000\n",
      "Done: 70000\n",
      "Done: 80000\n",
      "Done: 90000\n",
      "Done: 100000\n",
      "Done: 110000\n",
      "Done: 120000\n",
      "Routine finished. Process time 228.1412889957428 s\n"
     ]
    }
   ],
   "source": [
    "%run ./DeepRecommender/infer.py \\\n",
    "--path_to_train_data $TRAIN \\\n",
    "--path_to_eval_data $TEST \\\n",
    "--hidden_layers $HIDDEN \\\n",
    "--non_linearity_type $ACTIVATION \\\n",
    "--save_path  $MODEL_PATH \\\n",
    "--drop_prob $DROPOUT \\\n",
    "--predictions_path $INFER_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(path_to_predictions='preds.txt', round=False)\n",
      "####################\n",
      "RMSE: 0.9746437597050387\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "%run ./DeepRecommender/compute_RMSE.py --path_to_predictions=$INFER_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something more real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE_TITLES = os.path.join('data','movie_titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID    Year                         Title\n",
       "0        1  2003.0               Dinosaur Planet\n",
       "1        2  2004.0    Isle of Man TT 2004 Review\n",
       "2        3  1997.0                     Character\n",
       "3        4  1994.0  Paula Abdul's Get Up & Dance\n",
       "4        5  2004.0      The Rise and Fall of ECW"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = pd.read_csv(MOVIE_TITLES, names=['MovieID','Year','Title'], encoding = \"latin\")\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_gusta = [13, 191, 209, 316, 345, 468, 560, 752, 1066, 1551, 1601, 1905, 2189, 2252, 5507] \n",
    "me_gusta_pred = [2452, 2532, 2689, 3012, 3287]\n",
    "booo = [148, 270, 571, 1195, 1400, 1387, 1947, 1962, 2275, 2282, 2457, 2803, 3106, 3414, 4308]\n",
    "booo_pred = [4783, 4894, 5088, 5107, 5184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Lord of the Rings: The Return of the King: Ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>X2: X-Men United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Star Trek: Deep Space Nine: Season 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>316</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Futurama: Monster Robot Maniac Fun Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>345</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Star Trek: Voyager: Season 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>468</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>The Matrix: Revolutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>560</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Star Trek: Enterprise: Season 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>752</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>Star Trek: The Next Generation: Season 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1066</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>Superman: The Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1551</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Spider-Man 2: Bonus Material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1601</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>J.R.R. Tolkien and the Birth of The Lord of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>1905</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2189</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>The Hitchhiker's Guide to the Galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>2252</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Bram Stoker's Dracula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>5507</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Dragon Ball: Fortune Teller Baba Saga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MovieID    Year                                              Title\n",
       "12         13  2003.0  Lord of the Rings: The Return of the King: Ext...\n",
       "190       191  2003.0                                   X2: X-Men United\n",
       "208       209  1996.0               Star Trek: Deep Space Nine: Season 5\n",
       "315       316  1999.0      Futurama: Monster Robot Maniac Fun Collection\n",
       "344       345  1998.0                       Star Trek: Voyager: Season 5\n",
       "467       468  2003.0                            The Matrix: Revolutions\n",
       "559       560  2003.0                    Star Trek: Enterprise: Season 3\n",
       "751       752  1993.0           Star Trek: The Next Generation: Season 7\n",
       "1065     1066  1978.0                                Superman: The Movie\n",
       "1550     1551  2004.0                       Spider-Man 2: Bonus Material\n",
       "1600     1601  2004.0  J.R.R. Tolkien and the Birth of The Lord of th...\n",
       "1904     1905  2003.0  Pirates of the Caribbean: The Curse of the Bla...\n",
       "2188     2189  1981.0               The Hitchhiker's Guide to the Galaxy\n",
       "2251     2252  1992.0                              Bram Stoker's Dracula\n",
       "5506     5507  2002.0              Dragon Ball: Fortune Teller Baba Saga"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[titles['MovieID'].isin(me_gusta)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>2452</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2532</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Futurama: Vol. 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>2689</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Minority Report: Bonus Material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>3012</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Dragon Ball Z: World Tournament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>3287</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Terminator 3: Rise of the Machines: Bonus Mate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MovieID    Year                                              Title\n",
       "2451     2452  2001.0      Lord of the Rings: The Fellowship of the Ring\n",
       "2531     2532  1999.0                                   Futurama: Vol. 1\n",
       "2688     2689  2002.0                    Minority Report: Bonus Material\n",
       "3011     3012  2001.0                    Dragon Ball Z: World Tournament\n",
       "3286     3287  2003.0  Terminator 3: Rise of the Machines: Bonus Mate..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[titles['MovieID'].isin(me_gusta_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Sweet November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Sex and the City: Season 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>571</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>American Beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>1195</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Madonna: The Girlie Show: Live Down Under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1387</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>The Girl Next Door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1400</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Britney Spears: Britney in Hawaii: Live and More</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>1947</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Gilmore Girls: Season 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>1962</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>50 First Dates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>2275</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Madonna: What It Feels Like for a Girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>2282</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Disney Princess Stories: Vol. 2: Tales of Frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>2457</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>A Cinderella Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2803</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>3106</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>Ghost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>3414</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Pocahontas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>4308</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Beauty and the Beast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MovieID    Year                                              Title\n",
       "147       148  2001.0                                     Sweet November\n",
       "269       270  2001.0                         Sex and the City: Season 4\n",
       "570       571  1999.0                                    American Beauty\n",
       "1194     1195  1988.0          Madonna: The Girlie Show: Live Down Under\n",
       "1386     1387  1999.0                                 The Girl Next Door\n",
       "1399     1400  2000.0   Britney Spears: Britney in Hawaii: Live and More\n",
       "1946     1947  2002.0                            Gilmore Girls: Season 3\n",
       "1961     1962  2004.0                                     50 First Dates\n",
       "2274     2275  2001.0             Madonna: What It Feels Like for a Girl\n",
       "2281     2282  2005.0  Disney Princess Stories: Vol. 2: Tales of Frie...\n",
       "2456     2457  2004.0                                 A Cinderella Story\n",
       "2802     2803  1995.0                                Pride and Prejudice\n",
       "3105     3106  1990.0                                              Ghost\n",
       "3413     3414  1995.0                                         Pocahontas\n",
       "4307     4308  1999.0                               Beauty and the Beast"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[titles['MovieID'].isin(booo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>4783</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Felicity: Season 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>4894</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Celia Cruz: Fania Allstars in Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>5088</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Dirty Dancing: Bonus Material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>5107</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Barbra Streisand: Timeless: Live in Concert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5183</th>\n",
       "      <td>5184</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>'N Sync: Making of the Tour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MovieID    Year                                        Title\n",
       "4782     4783  1999.0                           Felicity: Season 2\n",
       "4893     4894  1998.0         Celia Cruz: Fania Allstars in Africa\n",
       "5087     5088  1987.0                Dirty Dancing: Bonus Material\n",
       "5106     5107  2001.0  Barbra Streisand: Timeless: Live in Concert\n",
       "5183     5184  2000.0                  'N Sync: Making of the Tour"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[titles['MovieID'].isin(booo_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
